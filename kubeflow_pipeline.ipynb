{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from datetime import datetime\n",
    "from kfp.components import InputPath, InputTextFile, OutputPath, OutputTextFile\n",
    "from kfp.components import func_to_container_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_train_data(cleaned_data_path: OutputPath('CSV')):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    from nltk.corpus import stopwords\n",
    "    import re\n",
    "    import numpy as np\n",
    "    \n",
    "    data = pd.read_csv('https://raw.githubusercontent.com/roshankonda98/kubeflow-sentiment-analysis/main/train_data.csv')\n",
    "    \n",
    "    processed_tweets = []\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = stopwords.words('english')\n",
    "    for t in data['text']:\n",
    "        process_tweet = re.sub(r'@\\w+','', t) #remove mentions from tweet\n",
    "        process_tweet = re.sub('[^a-zA-Z]',' ',process_tweet).lower().split() #remove any punctuation, numbers, and other characters\n",
    "        process_tweet = [w for w in process_tweet if not w in stop_words] #remove stop words\n",
    "        process_tweet = [stemmer.stem(w) for w in process_tweet] #reduce words to stem\n",
    "        processed_tweets.append(\" \".join(process_tweet)) \n",
    "\n",
    "    data['processed_tweets'] = processed_tweets\n",
    "    \n",
    "    export = data.to_csv(cleaned_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(cleaned_data_input: InputPath('CSV'), tr_x: OutputPath('NPY'), tr_y: OutputPath('NPY'), ts_x: OutputPath('NPY'), ts_y: OutputPath('NPY')):\n",
    "\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import numpy as np\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "    \n",
    "    data = pd.read_csv(cleaned_data_input)\n",
    "    data = data[['processed_tweets','airline_sentiment']] #get only required columns\n",
    "    data = data.dropna() #remove any nan values\n",
    "    print(data.head())\n",
    "    print(data.columns)\n",
    "    \n",
    "    \n",
    "    vocab_size = 7500\n",
    "    tokenizer = Tokenizer(num_words = vocab_size)\n",
    "    tokenizer.fit_on_texts(data['processed_tweets'])\n",
    "    \n",
    "    tweet_vectors = tokenizer.texts_to_sequences(data['processed_tweets'])\n",
    "    tweet_vectors = pad_sequences(tweet_vectors, padding = \"pre\")\n",
    "    \n",
    "    preds = pd.get_dummies(data[['airline_sentiment']]).values\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(tweet_vectors,preds,test_size = 0.2)\n",
    "    \n",
    "    with open(tr_x,'wb') as f:\n",
    "        np.save(f,train_x)\n",
    "        \n",
    "    with open(tr_y,'wb') as f:\n",
    "        np.save(f,train_y)\n",
    "        \n",
    "    with open(ts_x,'wb') as f:\n",
    "        np.save(f,test_x)\n",
    "        \n",
    "    with open(ts_y,'wb') as f:\n",
    "        np.save(f,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_model(tr_x: InputPath('NPY'), tr_y: InputPath('NPY'), model_output: OutputPath('H5')):\n",
    "    \n",
    "    from tensorflow.keras.layers import LSTM, Dropout, Dense, Embedding\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1' #make sure gpu is not used\n",
    "    \n",
    "    with open(tr_x, 'rb') as f:\n",
    "        train_x = np.load(f)\n",
    " \n",
    "    with open(tr_y, 'rb') as f:\n",
    "        train_y = np.load(f)\n",
    "        \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(7500,64,input_length = len(train_x[0])))\n",
    "    model.add(LSTM(64, activation = 'relu', return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(32, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy',optimizer = \"adam\",metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(train_x,train_y,epochs = 1)\n",
    "    \n",
    "    model.save(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gru_model(tr_x: InputPath('NPY'), tr_y: InputPath('NPY'), model_output: OutputPath('H5')):\n",
    "    \n",
    "    from tensorflow.keras.layers import GRU, Dropout, Dense, Embedding\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    import numpy as np\n",
    "    import os\n",
    "    \n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1' #make sure gpu is not used\n",
    "    \n",
    "    with open(tr_x, 'rb') as f:\n",
    "        train_x = np.load(f)\n",
    " \n",
    "    with open(tr_y, 'rb') as f:\n",
    "        train_y = np.load(f)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(7500,64,input_length = len(train_x[0])))\n",
    "    model.add(GRU(64, activation = 'relu', return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(32, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy',optimizer = \"adam\",metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(train_x,train_y,epochs = 1)\n",
    "    \n",
    "    model.save(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(input_model: InputPath('H5'), ts_x: InputPath('NPY'), ts_y: InputPath('NPY')):\n",
    "    \n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    with open(ts_x, 'rb') as f:\n",
    "        test_x = np.load(f)\n",
    " \n",
    "    with open(ts_y, 'rb') as f:\n",
    "        test_y = np.load(f)\n",
    "        \n",
    "    model = tf.keras.models.load_model(input_model)\n",
    "    \n",
    "    model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base image is public image created for this repo\n",
    "\n",
    "#convert python functions into docker containers \n",
    "clean_train_data_op = func_to_container_op(clean_train_data, base_image = 'dockerkonda1998/kubeflow-repo:ds-tensorflow')\n",
    "split_data_op = func_to_container_op(split_data, base_image = 'dockerkonda1998/kubeflow-repo:ds-tensorflow')\n",
    "train_lstm_model_op = func_to_container_op(train_lstm_model, base_image = 'dockerkonda1998/kubeflow-repo:ds-tensorflow')\n",
    "evaluate_model_op = func_to_container_op(evaluate_model, base_image = 'dockerkonda1998/kubeflow-repo:ds-tensorflow')\n",
    "train_gru_model_op = func_to_container_op(train_gru_model, base_image = 'dockerkonda1998/kubeflow-repo:ds-tensorflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name = \"Sentiment Analysis Pipeline\",\n",
    "    description = \"Predict Sentiment of Airline Tweets\"\n",
    ")\n",
    "\n",
    "def sentiment_analysis_pipeline():\n",
    "    cleaning_container = clean_train_data_op()\n",
    "    split_data_container = split_data_op(cleaning_container.output)\n",
    "    train_lstm_data_container = train_lstm_model_op(split_data_container.outputs['tr_x'], split_data_container.outputs['tr_y'])\n",
    "    train_gru_data_container = train_gru_model_op(split_data_container.outputs['tr_x'], split_data_container.outputs['tr_y'])\n",
    "    evaluate_lstm_model_container = evaluate_model_op(train_lstm_data_container.outputs['model_output'], split_data_container.outputs['ts_x'], split_data_container.outputs['ts_y'])\n",
    "    evaluate_gru_model_container = evaluate_model_op(train_gru_data_container.outputs['model_output'], split_data_container.outputs['ts_x'], split_data_container.outputs['ts_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/66c511b5-c0f9-47c8-b3f4-156ee812388f\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/830be29f-bedc-4e97-b487-3e2500d830c3\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=830be29f-bedc-4e97-b487-3e2500d830c3)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"sentiment_analysis_kubeflow\"\n",
    "run_name = experiment_name + \"-\" + datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "kfp.compiler.Compiler().compile(sentiment_analysis_pipeline,\"{}.zip\".format('sentiment_analysis_pipeline'))\n",
    "\n",
    "client.create_run_from_pipeline_func(sentiment_analysis_pipeline,\n",
    "                                     experiment_name = experiment_name,\n",
    "                                     run_name = run_name,\n",
    "                                     arguments = {}\n",
    "                                     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
